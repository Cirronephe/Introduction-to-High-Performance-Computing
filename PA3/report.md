# 稀疏矩阵-矩阵乘 大作业 实验报告

颜子俊 2023010828

## 优化方法及效果

以下实验 K=32，使用 collab 数据集。

### Warp divergence

#### 改变并行维度

让每个 warp 处理一个矩阵行，并让每个线程处理不同的 feature 列，让 warp 内线程处理相同的工作量。

**优化效果**： 1270us $\to$ 910us，效果显著，但是不同的 warp 之间负载差异较大。

### 负载不均衡

#### 矩阵行切分

将每个矩阵行切分，使得一个块内非零元数量不超过 32。运行时每个线程块处理一个 block，每个线程处理一个 feature 列，使得计算过程负载均衡。

**优化效果**：1270us $\to$ 900us，效果显著。

### 局部性

#### 预处理图数据

借助 METIS 对图中的点进行分组，依照组别对矩阵行列重排，使得行列均按照组号从小到大的顺序。相应对 vin 行重排，并在运行过程中注意还原 vout 写入位置。以此来增加数据的局部性。

**优化效果**：910us $\to$ 820us，效果一般。

### GPU 访存

#### 共享内存

改变并行维度或进行矩阵行切分后，一个 warp / 线程块 内访问的 vin 存在重叠，可先将这部分 vin 读入共享内存，降低访存开销。

**优化效果**：900us $\to$ 630us，效果显著。

## 实验结果

| Dataset      | Time (k=32) | Time (k=256) | Speedup (k=32) | Speedup (k=256) |
| ------------ | ----------- | ------------ | -------------- | --------------- |
| arxiv        | 0.000349534 | 0.00294472   | 2.09×          | 1.01×           |
| collab       | 0.000630518 | 0.00519869   | 2.01×          | 1.00×           |
| citation     | 0.00950029  | 0.0760302    | 1.73×          | 1.04×           |
| ddi          | 0.000237386 | 0.00169042   | 2.70×          | 0.91×           |
| protein      | 0.010092    | 0.102274     | 2.44×          | 0.79×           |
| ppa          | 0.0100517   | 0.0865454    | 1.83×          | 0.98×           |
| reddit.dgl   | 0.0221037   | 0.21946      | 2.20×          | 0.92×           |
| products     | 0.0319841   | 0.25927      | 1.75×          | 1.00×           |
| youtube      | 0.00247611  | 0.0157862    | 1.47×          | 0.91×           |
| amazon_cogdl | 0.061541    | 0.560363     | 2.03×          | 0.92×           |
| yelp         | 0.00343602  | 0.0305679    | 1.91×          | 0.98×           |
| wikikg2      | 0.00445976  | 0.0237214    | 1.60×          | 0.70×           |
| am           | 0.00258972  | 0.0140796    | 1.45×          | 0.95×           |

## 说明

与包一鸣同学进行了讨论。